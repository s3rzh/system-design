Разделение системы (веб-сервер) на веб-уровень (веб-сервер) и уровень данных (БД) позволяет *масштабировать* эти компоненты независимо друг от друга.

**Реляционные БД** (MySQL, Oracle, PostgreSQL и т. д.) предоставляют и хранят данные в таблицах и строках. С помощью SQL можно выполнять операции объединения между различными таблицами базы данных.

**Нереляционные БД** также называют *NoSQL* (CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB и т. д.). Эти базы данных делятся на четыре категории: хранилища «ключ–значение», графовые, столбцовые и документные. Нереляционные БД обычно неподдерживают операции соединения. Нереляционные БД могут быть подходящим решением, если:
  - ваше приложение нуждается в крайне низкой латентности (**Latency** - это время ожидания, которое требуется на доставку пакета данных от источника к пункту назначения.);
  - ваши данные не структурированы или не имеют никаких реляционных связей;
  - вам нужно лишь сериализовать и десериализовать свои данные(JSON, XML, YAML и т. д.). *Сериализация и десериализация* - это процессы преобразования данных из одной формы в другую с целью сохранения или передачи информации.;
  - вам нужно хранить огромные объемы данных.

**Вертикальное масштабирование**, известное как наращивание, — это процесс повышения мощности ваших серверов (процессоров, памяти оперативной или дисковой и т. д.). Вертикальное масштабирование отлично подходит для задач с небольшим трафиком. Его главным преимуществом является простота (добавить несколько планок RAM просто). Но есть ряд серьезных ограничений:
  - Вертикальное масштабирование имеет жесткий лимит. Ресурсы отдельно взятого сервера нельзя увеличивать бесконечно.
  - Вертикальное масштабирование не предусматривает отказоустойчивость и резервирование избыточных ресурсов. Если один из серверов выйдет из строя, веб-сайт/приложение станет полностью недоступным.
    
**Горизонтальное масштабирование**, которое еще называют расширением, заключается в добавлении новых серверов в пул ресурсов. Лучше подходит для крупномасштабных приложений.

**Балансировщик нагрузки** равномерно распределяет входящий трафик между веб-серверами (чтобы один сервер не вышел из строя после внезамно возросшей нагрузки от большого кол-ва пользователей). Те запросы от пользователей идут на IP-адрес балансировщика нагрузки (который был получен от DSN сервера). По соображениям безопасности для взаимодействия между серверами используются внутренние IP-адреса. Внутренний IP доступен только для серверов из той же *сети*, но не виден из интернета. Балансировщик нагрузки взаимодействует с веб-серверами с помощью внутренних IP-адресов. За счет добавления балансировщика нагрузки и второго сервера нам удается решить проблему с отсутствием отказоустойчивости и улучшить доступность веб-уровня. Т.е.:
 - Если сервер 1 выходит из строя, весь трафик перенаправляется к серверу 2. Благодаря этому веб-сайт остается доступным. Чтобы сбалансировать нагрузку, мы добавим в пул серверов новый исправный веб-сервер.
 - Если посещаемость веб-сайта стремительно растет и для обслуживания трафика не хватает двух серверов, балансировщик нагрузки может изящно справиться с этой проблемой. Для этого достаточно расширить пул серверов, и балансировщик начнет автоматически
передавать запросы новым веб-серверам.

**Репликая** - те создание копии БД, решает проблему отказоустойчивости и резервирования для уровня БД. Репликация баз данных обычно используется в режиме "ведущий–ведомый", где роль ведущего сервера играет оригинал (master), а его копии являются ведомыми (slave). Ведущая база данных обычно поддерживает только операции записи. Ведомые БД получают от ведущей копии ее содержимого и поддерживают только операции чтения (если ведомая БД только одна - то после её падения операции чтения перенаправятся на ведущую, если же более одной - то перенаправятся на остальным ведомые). Если ведущая база данных выйдет из строя, ее место (временно) займет одна из ведомых.
Все команды для модификации данных, такие как *вставка*, *удаление* или *обновление*, должны направляться ведущей базе данных. В большинстве приложений чтение происходит намного чаще, чем запись, поэтому ведомых БД обычно больше, чем ведущих. Преимущества репликации базы данных:
  - Повышенная производительность. В модели «ведущий–ведомый» все операции записи и обновления происходят на ведущих узлах, а операции чтения распределяются между ведомыми. Это улучшает производительность, увеличивая количество запросов, которые можно обрабатывать параллельно.
  - Надежность. Если один из ваших серверов с базой данных сломается из-за стихийного бедствия, такого как тайфун или землетрясение, данные не будут утеряны. Вам не нужно беспокоиться о потере данных, так как они реплицируются по разным местам.
  - Высокая доступность. За счет репликации данных по разным местам ваш веб-сайт будет продолжать работать, даже если одна из БД вый­дет из строя, поскольку у вас по-прежнему будет доступ к данным, размещенным на другом сервере.

**Кэш** — это участок памяти (оперативной, те быстрой), в который временно записываются результаты ресурсоемких ответов или данных, к которым часто обращаются. Это позволяет ускорить обслуживание последующих запросов (тк многократное обращение к БД существенно влияет на производительность в худшую сторону). Преимущество отдельного кэша - это возможность масштабировать его. Если данные есть в кэше, читаем их из кэша, если данных нет в кэше - читаем из БД и сохраняем их в кэш. Эта стратегия называется *кэшем сквозного чтения*.

Некоторые аспекты использования кэша:
  - Определитесь с тем, когда будет использоваться кэш. Это лучше делать в ситуациях, когда чтение данных происходит часто, а изменение — редко. Поскольку кэшированные данные хранятся в энергозависимой памяти, сервер кеширования не подходит для постоянного хранения. Например, если он перезапустится, все данные, хранившиеся в памяти, будут утрачены. В связи с этим данные необходимо записывать в постоянные хранилища.
  - Выбор срока действия. Рекомендуется реализовать механизм, ограничивающий срок действия кэша. Просроченные данные немедленно удаляются. Если такого механизма нет, данные будут храниться в памяти постоянно. Срок действия лучше не делать слишком коротким, иначе система будет слишком часто обновлять данные, загружая их из БД. С другой стороны, из-за слишком длинного срока действия данные могут оказаться неактуальными.
  - Согласованность. Это подразумевает синхронизацию данных в хранилище и кэше. Несогласованность может возникнуть из-за того, что операции изменения данных в хранилище и кэше выполняются не за одну транзакцию. При масштабировании системы в пределах нескольких регионов может быть непросто поддерживать согласованность.
  - Предотвращение сбоев. Наличие лишь одного сервера кэширования может оказаться потенциальной единой точкой отказа (single point of failure, SPOF), которая, согласно английской Википедии, имеет следующее определение: «Единая точка отказа — это компонент, выход из строя которого приводит к прекращению работы всей системы». В связи с этим, чтобы избежать SPOF, рекомендуется использовать несколько серверов кэширования, размещенных в разных центрах обработки данных (ЦОД). А еще можно выделить какой-нибудь дополнительный объем памяти: это создаст буфер на случай, если память начнет использоваться более активно. 
  - Политика вытеснения. Когда кэш полностью заполнен, любой запрос на добавление новых элементов может привести к удалению существующих. Это называют вытеснением кэша. Самой по­пулярной политикой считается вытеснение давно неиспользуемых данных (least-recently-used, LRU). Для разных ситуаций могут также подойти вытеснение наименее часто используемых данных (least-frequently-used, LFU) или метод «первым пришел, первым ушел» (FIFO, first-in-first-out).

**CDN** — это сеть географически распределенных серверов, которая используется для доставки статического содержимого. Серверы CDN кэшируют такие статические файлы, как изображения, видео, CSS, JavaScript и т. д. Принцип работы - когда пользователь посещает веб-сайт, ближайший к нему сервер CDN доставляет статическое содержимое (файл), но если в кэше сервера CDN нет запрашиваемого файла он запрашивает этот файл
из оригинального источника, например веб-сервера или онлайн-хранилища вроде Amazon S3 (или др. S3-подобного). Источник (веб-сервера или онлайн-хранилища) возвращает серверу CDN файл вместе с дополнительным HTTP-заголовком TTL (Time-to-Live — «время жизни»), который определяет, как долго изображение будет находиться в кэше. CDN кэширует файл и возвращает его пользователю. Оно остается в кэше CDN, пока не истечет срок TTL. При повтороном обращени к файлу - если срок TTL еще не истек, изображение возвращается из кэша.

Нюансы использования CDN:
  - Стоимость. Серверы CDN предоставляются сторонними компаниями, а перемещение данных в CDN и из CDN стоит денег. Кэширование нечасто используемых ресурсов не даст существенных преимуществ, поэтому из CDN их лучше убрать.
  - Подбор подходящего срока годности кэша. Для содержимого, которое зависит от времени, необходимо предусмотреть срок годности кэша. Он должен быть не слишком длинным, но и не слишком коротким. В первом случае содержимое может потерять свою актуальность, а во втором — привести к повторной перезагрузке содержимого с исходных серверов в CDN.
  - Возможность сбоев. Вы должны подумать о том, как ваши веб-сайты/приложения будут справляться с недоступностью CDN. Если CDN временно выходит из строя, у клиента должна быть возможность обнаружить эту проблему и запросить ресурсы из исходного источника.
  - Аннулирование файлов. Файлы можно удалять из CDN до истечения их срока годности одним из следующих способов:
    - аннулировать объект CDN с помощью API-интерфейсов, предоставляемых поставщиками CDN;
    - использовать версионирование, чтобы возвращать разные версии объектов. Для этого к URL-адресу можно добавить параметр с номером версии. Например, версия 2 может быть представлена строкой запроса: image.png?v=2.

Для *горизонтального масштабирования* веб-уровня (веб-сервиса, веб-сервер). Для этого нужно вынести из него состояние, те stateless (например, информацию о пользовательских сеансах).  Данные сеансов рекомендуется записывать в постоянные хранилища, такие как реляционные БД или NoSQL. Каждый веб-сервер в кластере может запросить состояние из БД. Отсутствие состояния делает систему более простой, надежной и масштабируемой.

От того, хранит сервер состояние или нет, зависит, будет ли он «помнить» данные клиента (состояние) между разными запросами. Чтобы пользователь попадал именно на тот сервер, на котором хранятся его данные сеанса - балансировщик нагрузки должен всегда перенапралвять его на один и тот же сервер (бу алансировщиков нагрузки для этого предусмотрены *липкие сеансы*) иначе пользователь будет не аутентифицирован (те распознан, тк данных о нём на этом сервере нет).

Подход *липкие сеансы*  увеличивает накладные расходы. Из-за него добавление и удаление серверов дается с трудом. Также возникают проблемы, если сервер выходит из строя.

***Автомасштабирование** означает, что добавление и удаление веб-серверов происходит автоматически в зависимости от объемов трафика за счет добавления и удаления серверов с учетом нагрузки.

**ЦЕНТРЫ ОБРАБОТКИ ДАННЫХ** (ЦОД) - используются для улучшения *доступности* и *UX*, их должно быть несколько. Те с помощью GeoDNS направляются к ближайшему центру обработки данных. В случае любого серьезного нарушения работы одного из центров обработки данных мы перенаправляем весь трафик к исправному ЦОД.

**UX** расшифровывается как *user experience* ― «пользовательский опыт». Это то, каким образом пользователь взаимодействует с интерфейсом и насколько сайт или приложение для него удобны.

**GeoDNS** (система географических доменных имен) - это процесс распределения трафика на основе местоположения запросов. Его также называют *директором трафика* или *директором глобального трафика*. Используя сервис GeoDNS, вы можете эффективно оптимизировать трафик к доменам за счет использования географической маршрутизации.

Для реализации архитектуры с несколькими центрами обработки данных необходимо решить несколько технических вопросов:
  - Перенаправление трафика. Необходимы эффективные инструменты для направления трафика к подходящему ЦОД. GeoDNS позволяет выбирать центр обработки данных, который находится ближе всего к пользователю.
  - Синхронизация данных. Пользователи могут работать с разными локальными базами данных и кэшами в зависимости от региона. В случае сбоя трафик может быть перенаправлен к ЦОД, в котором нет запрашиваемых данных. Распространенным решением является репликация данных между несколькими ЦОД.
  - Тесты и развертывание. В конфигурации с несколькими ЦОД тестирование веб-сайта/приложения необходимо проводить в разных местах. Автоматические средства развертывания незаменимы в поддержании согласованности всех ЦОД.

Чтобы еще сильнее улучшить масштабируемость системы, ее следует разделить на компоненты; это позволит масштабировать их независимо друг от друга, а для взаимодействия этих компонентов в распределенных системах хорошо подходят очереди сообщений.

**Очередь сообщений** — это устойчивый компонент, который загружается в память и поддерживает асинхронное взаимодействие. Он служит буфером и распределяет асинхронные запросы. Очередь сообщений имеет
простую базовую архитектуру. Сервисы ввода, так называемые производители/издатели, создают сообщения и публикуют их в очереди. Другие сервисы или серверы, которые называют потребителями/подписчиками,
подключаются к очереди, читаю сообщения и выполняют действия, определенные в этих сообщениях. Очередь сообщений помогает сделать систему менее связанной и более устойчивой к отказам.

Благодаря разделению очередь сообщений является предпочтительной архитектурой для создания *масштабируемых* и *надежных* приложений. Производитель может публиковать сообщения в очереди, даже если
потребитель не в состоянии их обработать. И наоборот — потребитель может считывать сообщения из очереди, даже если производитель недоступен. Производитель и потребитель могут масштабироваться независимо друг от друга. Когда очередь становится слишком большой, для сокращения времени обработки добавляются новые рабочие узлы. Если же очередь в основном пустует, количество рабочих узлов можно уменьшить.

**Логирование**. Мониторинг логов играет важную роль, помогая выявлять в системе *ошибки* и *проблемы*. Логи можно отслеживать на каждом отдельном сервере, но есть также инструменты, позволяющие собирать их
в централизованном сервисе ради *удобства поиска* и *просмотра*.

**Метрики**. Сбор разного рода метрик помогает лучше понять предметную область и оценить работоспособность системы. Вам может пригодиться что-то из следующего:
  - метрики уровня сервера: процессор, память, дисковый ввод/вывод и т. д.;
  - агрегированные метрики: производительность всего уровня базы данных, уровня кэша и т. д.;
  - ключевые бизнес-метрики: суточное количество активных пользователей, удержание, доход и т. д.

**Автоматизация**. Когда система становится большой и сложной, для повышения продуктивности необходимо разработать новые или использовать уже готовые средства автоматизации. Рекомендуется применять
непрерывную интеграцию — это когда каждая фиксация кода автоматически проверяется, что помогает обнаруживать проблемы на ранних этапах. Кроме того, автоматизация процессов сборки, тестирования,
развертывания и других может существенно повысить продуктивность разработчиков.

Есть два общих подхода к масштабированию БД: **вертикальный** и **горизонтальный**.

**Вертикальное масштабирование** (или наращивание) подразумевает повышение производительности существующего компьютера за счет добавления ресурсов процессора, памяти, диска и т. д. Серверы баз данных бывают довольно мощными. У вертикального масштабирования есть серьезные недостатки:
  - Можно добавлять к своему серверу дополнительные ресурсы процессора, памяти и т. д., но аппаратные ограничения игнорировать не получится. Если у вас много пользователей, одного сервера будет недостаточно.
  - Повышенный риск возникновения единой точки отказа.
  - Вертикальное масштабирование имеет высокую общую стоимость. Мощные серверы очень дорогие.

**Горизонтальное масштабирование** (или расширение) заключается в добавлении новых серверов. 

**Шардинг** позволяет разделить крупные наборы данных на более мелкие и простые в использовании части, которые называют *шардами*. Все шарды имеют одну и ту же схему, но каждый из них хранит уникальные данные (например, при каждом обращении к данным используется функция хеширования, которая находит подходящий шард. Например, функция хеширования имеет вид user_id % 4. Если результат равен 0, для хранения и извлечения данных используется сегмент 0. Если результат равен 1, выбирается сегмент 1.). При реализации стратегии сегментирования самый важный фактор — это выбор ключа. Ключ шардинга (или ключ раздела) состоит из одного или нескольких столбцов, на основе которых происходит распределение данных. Так же, при выборе ключа шардинга один из важнейших критериев — возможность *равномерного* распределения данных. Шардинг отлично подходит для масштабирования баз данных. Но он и усложняет систему, и создает дополнительные трудности:
  - **Повторное сегментирование данных**. Это может понадобиться, когда 1) отдельный шард полностью заполняется из-за стремительного развития системы или 2) некоторые шарды заполняются быстрее других из-за неравномерного распределения данных. В такой ситуации необходимо обновить функцию сегментирования и переместить имеющиеся данные. Для решения этой проблемы зачастую применяют *согласованное хеширование* (о нем позже).
  - Проблема знаменитостей. Слишком частое обращение к определенному шарду может вызвать перегрузку сервера. Представьте, что информация о Криштиану Роналду и Эксле Роузе очутилась в одном и том же сегменте. Если речь идет о социальных приложениях, этот сегмент будет перегружен операциями чтения. Для решения этой проблемы, возможно, придется выделить по отдельному шарду для каждой знаменитости. Может случиться так, что каждый сегмент потребует дальнейшего разделения.
  - **Соединение и денормализация**. После сегментирования базы данных между несколькими серверами становится сложно выполнять операции соединения, охватывающие несколько шардов. Распространенное решение состоит в денормализации базы данных таким образом, чтобы запросы могли выполняться в рамках одной таблицы.

Суммарно шаги, которые предпринимаются в ходе масштабирования системы для поддержки миллионов пользователей:
  - веб-уровень не должен хранить состояния;
  - резервирование должно быть предусмотрено на каждом уровне;
  - кэширование данных следует проводить как можно более активно;
  - система должна поддерживать больше одного центра обработки данных;
  - статические ресурсы нужно хранить в CDN;
  - для масштабирования данных следует применять шардинг;
  - уровни должны быть разделены на отдельные сервисы;
  - необходимо выполнять мониторинг системы и использовать средства автоматизации.


Продолжительности типичных компьютерных операций (некоторые из этих показателей потеряли актуальность в связи с повышением производительности компьютеров):
  - Обращение к кэшу L1: 0,5 нс (наносекунда)
  - Ошибочное предсказание перехода: 5 нс
  - Обращение к кэшу L2: 7 нс
  - Блокирование/разблокирование мьютекса: 100 нс
  - Обращение к основной памяти: 100 нс
  - Сжатие 1 Кб с помощью Zippy: 10 000 нс = 10 мкс (микросекунда)
  - Отправка 2 Кб по сети 1 Гбит/с: 20 000 нс = 20 мкс
  - Последовательное чтение из памяти 1 Мб: 250 000 нс = 250 мкс
  - Перемещение пакета туда и обратно внутри одного ЦОД: 500 000 нс = 500 мкс
  - Время поиска по диску: 10 000 000 нс = 10 мс (миллисекунда)
  - Последовательное чтение 1 Мб из сети: 10 000 000 нс = 10 мс
  - Последовательное чтение 1 Мб с диска: 30 000 000 нс = 30 мс
  - Передача пакета из Калифорнии в Нидерланды и обратно: 150 000 000 нс = 150 мс

**Выводы**: 
  - память быстрая, а диск медленный;
  - по возможности следует избегать поиска по диску;
  - простые алгоритмы сжатия отличаются высокой скоростью;
  - прежде чем отправлять данные по интернету, их по возможности нужно сжимать;
  - центры обработки данных обычно находятся в разных регионах, и передача информации между ними занимает время.

**Высокая доступность** — это способность системы долго и непрерывно находиться в рабочем состоянии. Она измеряется в процентах. 100 % означает, что сервис никогда не простаивает. У большинства сервисов
доступность варьируется от 99 % и 100 %.

**SLA** (service level agreement) - те соглашение об уровне услуг, это соглашение между вами (поставщиком) и вашим клиентом, которое официально определяет уровень беспрерывной работы вашего сервиса. Облачные провайдеры предлагают SLA от 99,9 % и выше (чем больше девяток, тем лучше, например 99,9999 %).

НИЖЕ ПРИМЕР ОЦЕНКИ ТРЕБОВАНИЙ К QPS И ХРАНИЛИЩУ.

Предположения:
  - 300 миллионов активных пользователей в месяц;
  - 50 % из них пользуются сервисом ежедневно;
  - пользователи в среднем публикуют по 2 поста в день;
  - 100 % постов содержат медиаданные;
  - данные хранятся на протяжении 5 лет.

Оценки:
  - ежедневные активные пользователи (daily active users, DAU) = 300 миллионов * 50 % = 150 миллионов;
  - запросов в секунду (queries per second, QPS) = 150 миллионов * 2 поста / 24 часа / 3600 секунд = ~3500 запросов в секунду;
  - пиковый показатель QPS = 2 * QPS = ~7000 запросов в секунду.

Оценка места, необходимого для хранения данных:
  - средний размер поста:
    - post_id — 64 байта;
    - текст — 140 байтов;
    - медиаданные — 1 Мб;
  - объем данных: 150 миллионов * 2 поста * 10% (или 1/10) * 1 Мб = 30 Тб в день;
  - объем данных за 5 лет: 30 Тб * 365 дней в году * 5 лет = ~55 Пб.


 Общие этапы интервью.

1-ы шаг. Понять задачу. Подумайте и задайте правильные вопросы, чтобы уточнить требования и допущения, сделать подходящие предположения и собрать всю информацию, необходимую для создания системы. Так же свои мысли лучше записать. 3–10 минут.
Примеры вопросов:
  - какие именно возможности мы будем реализовывать?
  - сколько пользователей у нашего продукта?
  - как скоро ожидается наращивание мощностей? Какой масштаб планируется через 3 месяца, полгода, год?
  - как выглядит технологический стек компании? Какие существующие сервисы можно применить для упрощения архитектуры?

2-ой шаг. Пытаемся выработать общее решение и получить аппрув от интервьюера. 10–15 минут.
  - Предложите начальный план архитектуры. Поинтересуйтесь мнением интервьюера. Относитесь к нему как к члену своей команды, с которым вы вместе работаете.
  - Нарисуйте на доске блок-схемы (крупноблочно) с ключевыми компонентами, такими как клиенты (мобильные/браузерные), API-интерфейсы, веб-серверы, хранилища данных, кэши, CDN, очереди сообщений и т. д.
  - Выполните приблизительные расчеты, чтобы понять, соответствует ли ваше решение масштабу задачи. Рассуждайте вслух. Прежде чем что-то считать, пообщайтесь с интервьюером.

По возможности пройдитесь по нескольким конкретным сценариям использования. Это поможет вам сформировать общую архитектуру и, скорее всего, обнаружить крайние случаи, о которых вы еще не думали.

3-ий шаг. Глубокое (подробное) погружение в проектирование.  10–25 минут.
Работая совместно с интервьюером, вы должны определить компоненты архитектуры и назначить им тот или иной приоритет. Например, если вы проектируете сервис для сокращения URL-адресов, особый интерес будет представлять функция хеширования, превращающая длинный адрес в короткий. В системе обмена сообщениями двумя интересными аспектами являются снижение латентности и поддержка онлайн/офлайн-статусов.  Старайтесь не углубляться в ненужные подробности.

4-ый шаг. Подведение итогов, вопросы про улучшение, уточняющие вопросы. 3–5 минут.
  - Интервьюер может попросить вас обозначить узкие места системы и обсудить потенциальные улучшения. Всегда можно что-то улучшить. Это отличная возможность продемонстрировать свое критическое мышление.
  - Возможно, стоит провести краткий обзор вашей архитектуры, особенно если вы предложили несколько решений.
  - Будет интересно поговорить о внештатных ситуациях, таких как поломка серверов, разрыв сети и т. д.
  - Стоит затронуть эксплуатационные вопросы. Как вы отслеживаете метрики и журналы ошибок? Как выкатывается система?
  - Проведение следующего этапа масштабирования — тоже весьма интересная тема. Например, если ваша текущая архитектура поддерживает 1 миллион пользователей, какие изменения нужно внести, чтобы увеличить эту цифру до 10 миллионов?
  - Если еще остается время, предложите дальнейшие улучшения.

**Ограничитель трафика** используется в сетевых системах для управления скоростью передачи данных от клиента или сервиса. В мире HTTP он ограничивает количество запросов, которые пользователь может отправить за определенный промежуток времени. Если исчерпано максимальное число API-запросов, заданное ограничителем трафика, все последующие вызовы блокируются. 

Вот несколько примеров:
  - пользователь может создать не больше двух сообщений в секунду;
  - с одного IP-адреса можно создать не больше 10 учетных записей в день;
  - на одном устройстве можно получить не больше 5 наград в неделю.

Преимущества использования компонента "Ограничитель трафика" в API:
  - Предотвращение нехватки ресурсов, вызванной DoS-атакой (Denial of Service — «отказ в обслуживании»). Ограничитель трафика предотвращает как спланированные, так и непредумышленные DoS-атаки, блокируя избыточные вызовы.
  - Экономия бюджета. Ограничение избыточных запросов позволяет освободить часть серверов и выделить больше ресурсов для высокоприоритетных API. Это чрезвычайно важно для компаний, которые используют платные сторонние API. Например, вам может стоить
денег каждое обращение к внешним API, которые позволяют проверить кредитные средства, отправить платеж, получить записи медкарты и т. д. Ограничение количества вызовов играет важную роль в снижении расходов.
  - Предотвращение перегрузки серверов. Чтобы снизить нагрузку на серверы, ограничитель трафика фильтрует лишние запросы, исходящие от ботов или недобросовестных пользователей.

Ограничение трафика можно реализовать с помощью разных алгоритмов, каждый из которых имеет как преимущества, так и недостатки. Он может быть релизован на клиентской стороне или серверной те на стороне API.

**Алгоритм маркерной корзины** (token bucket) работает следующим образом:

  - Маркерная корзина — это контейнер с заранее определенной емкостью (размер корзины). В нее регулярно помещают маркеры/житоны. Когда она окончательно заполняется, маркеры больше не добавляются (последующие маркеры отбрасываются).
  - Затем с интервалом в минуту (частота пополнения) - добавляем маркеров до полной корзины (до размера корзины). Те по сути, если ёмкость равна 4 - мы ограничиваем максимум 4 запроса в минуту.

Сколько корзин нам нужно? Примеры:

  - Для разных конечных точек API обычно нужны разные корзины. Например, если пользователь публикует 1 сообщение в секунду, добавляет 150 друзей в день и «лайкает» 5 сообщений в секунду, каждому пользователю нужно выделить 3 корзины.
  - Если нам нужно фильтровать запросы в зависимости от IP-адресов, каждому IP-адресу требуется корзина.
  - Если система допускает не больше 10 000 запросов в секунду, логично предусмотреть глобальную корзину для всех запросов.

Преимущества:
  - легкая реализация;
  - эффективное потребление памяти;
  - маркерная корзина может справиться с короткими всплесками трафика; пока в корзине остаются маркеры, запрос обрабатывается.

Недостатки:
  - несмотря на то что алгоритм принимает лишь два параметра (размер корзины и частота пополнения), подобрать подходящие значения может быть непросто.


**Алгоритм дырявого ведра** (leaking bucket) - первый обрабатывает запросы с фиксированной скоростью (обычно по принципу FIFO). Работает следующим образом:
  
  - при поступлении запроса система проверяет, заполнена ли очередь. Запрос добавляется в очередь при наличии места;
  - в противном случае запрос отклоняется;
  - запросы извлекаются из очереди и обрабатываются через равные промежутки времени.

Алгоритм дырявого ведра принимает два параметра:
  - размер ведра: равен размеру очереди; очередь хранит запросы, которые обрабатываются с постоянной скоростью;
  - скорость утечки: определяет, сколько запросов можно обработать за определенный промежуток времени (обычно за 1 секунду).

Преимущества:
  - эффективное потребление памяти при ограниченном размере очереди;
  - запросы обрабатываются с постоянной скоростью, поэтому этот алгоритм подходит для задач, которые требуют стабильной скорости обработки.

Недостатки:
  - всплеск трафика наполняет очередь старыми запросами, и, если их вовремя не обработать, новые запросы будут отклоняться;
  - несмотря на то что алгоритм принимает лишь два параметра, подобрать подходящие значения может быть непросто.

**Счетчик фиксированных интервалов** (fixed window counter). Работает следующим образом:
  - Алгоритм делит заданный период времени на одинаковые интервалы и назначает каждому из них счетчик.
  - Каждый запрос инкрементирует счетчик на 1.
  - Как только счетчик достигнет заранее заданного лимита, новые запросы начинают отклоняться, пока не начнется следующий интервал.

Преимущества:
  - эффективное потребление памяти;
  - понятность;
  - сброс квоты доступных запросов в конце временного интервала подходит для ряда задач.

Недостатки:
  - всплески трафика на границе временных интервалов могут привести к приему запросов, количество которых превышает квоту.

**Журнал скользящих интервалов** (sliding window log). Работает следующим образом:
  - Алгоритм следит за временными метками запросов. Временные метки обычно хранятся в кэше, например, в упорядоченных множествах Redis
  - Когда поступает новый запрос, все просроченные запросы отбрасываются. Просроченными считают запросы раньше начала текущего временного интервала.
  - Временные метки новых запросов заносятся в журнал.
  - Если количество записей в журнале не превышает допустимое, запрос принимается, а если нет — отклоняется.

Преимущества:
  - ограничение трафика, реализованное с помощью этого алгоритма, получается очень точным; на любом скользящем интервале запросы не превышают заданный лимит.

Недостатки:
  - этот алгоритм потребляет много памяти, потому что даже в случае отклонения запроса соответствующая временная метка записывается в журнал.

**Счетчик скользящих интервалов** (sliding window counter). Счетчик скользящих интервалов — это гибридный подход, сочетающий в себе два предыдущих алгоритма. Его можно реализовать двумя разными способами.

Преимущества:
  - сглаживание всплесков трафика: текущая частота запросов зависит от той, которая использовалась на предыдущем интервале.
  - экономия памяти.

Недостатки:
  - работает только для нежестких ретроспективных интервалов; частота получается приблизительной, так как подразумевается, что запросы на предыдущем интервале распределены равномерно. Но это может быть не настолько серьезной проблемой, как кажется на
первый взгляд.

Правила ограничения трафика  обычно записываются в конфигурационные файлы и сохраняются на диске (например yaml, на рабочих узлах), а промежуточный ограничитель считывает из кэша (значения в кэше обновляют рабочие узлы, сколько запросов в данный момент, временные метки).

Когда запрос отклоняется, API возвращает клиенту HTTP-ответ с кодом 429 («слишком много запросов»). В зависимости от ситуации отклоненные запросы могут быть записаны в очередь, чтобы позже их можно было обработать. Например, если некоторые заказы отклоняются из-за перегруженности системы, мы можем отложить их на потом.

Как клиент узнает, что его трафик ограничивается? И откуда он может узнать количество запросов, которые он может выполнить, прежде чем вступят в силу ограничения? Ответ заключается в заголовках HTTP-ответов. Ограничитель трафика возвращает клиентам следующие HTTP-заголовки:
  - X-Ratelimit-Remaining. Количество допустимых запросов, которое остается в текущем интервале.
  - X-Ratelimit-Limit. Количество вызовов, доступных клиенту в каждом временном интервале.
  - X-Ratelimit-Retry-After. Количество секунд, которое должно пройти, прежде чем ваши запросы престанут отклоняться. Плюс код ошибки 429.


Ограничитель трафика обязательно должен быть распределен по разным центрам обработки данных, ведь чем дальше пользователь находится от ЦОД, тем выше латентность. Данные должны синхронизироваться в соответствии с моделью *отложенной согласованности* (чтобы это не значило).

После реализации ограничителя трафика необходимо собрать аналитические данные, чтобы проверить, насколько он эффективен. Нас в основном интересует эффективность:
  - алгоритма ограничения трафика;
  - правил ограничения трафика.

Если правила ограничения трафика будут слишком строгие - будет теряться много корректных запросов (те нужно будет их ослабить). Ограничитель трафика также может становиться неэффективным во время внезапных всплесков активности, таких как распродажи. Чтобы этого не произошло, можно воспользоваться другим алгоритмом, который лучше справляется с такими условиями. Хорошим вариантом будет алгоритм *маркерной корзины*.

Для обеспечения горизонтального масштабирования запросы/данные должны распределяться между серверами эффективно и равномерно. Для этого зачастую используется *согласованное хеширование*.

Если у вас есть n кэширующих серверов, балансирование нагрузки обычно обеспечивается с помощью следующего метода хеширования: serverIndex = hash(key) % N, где N — размер пула серверов. 
Такой подход работает хорошо, когда пул серверов имеет *фиксированный размер*, а данные распределены равномерно. Но при добавлении новых или удалении существующих серверов возникают проблемы (а именно большинство клиентов начнут извлекать закэшированные данные не из тех серверов, это тн кэш-промахи). Согласованное хеширование — эффективный метод борьбы с этой проблемой.

Согласованное хеширование - вид хеширования, отличающийся тем, что когда хеш-таблица перестраивается (например, когда выходит один из серверов и строя), только K/n ключей в среднем должны быть переназначены, где K — число ключей и n — число слотов (серверов).  В противоположность этому, в большинстве традиционных хеш-таблиц изменение количества слотов вызывает переназначение почти всех ключей.

Алгоритм согласованного хеширования состоит из двух основных этапов:
  - серверы и ключи наносятся на кольцо с использованием равномерно распределенной хеш-функции;
  - чтобы определить, какому серверу принадлежит ключ, нужно пройти по часовой стрелке от позиции ключа к ближайшему серверу на кольце.

У этого подхода есть две проблемы. Первая: учитывая, что серверы могут добавляться и удаляться, их отрезки на кольце не могут иметь фиксированный размер. Отрезок — это пространство хеширования между двумя
соседними серверами. Размер отрезков, назначаемых каждому серверу, может оказаться как очень маленьким, так и достаточно большим. Вторая проблема состоит в том, что распределение ключей на кольце может быть неравномерным. Для решения этих проблем используется методика, известная как *виртуальные узлы* или *реплики*.

Виртуальный узел ссылается на настоящий; каждый сервер представлен на кольце несколькими виртуальными узлами. Благодаря виртуальным узлам каждый сервер отвечает сразу за несколько отрезков. Чтобы узнать, на каком сервере хранится ключ, мы переходим в его позицию на кольце и двигаемся по часовой стрелке к ближайшему виртуальному узлу. Чем больше виртуальных узлов, тем равномернее становится распределение ключей. Это вызвано уменьшением стандартного отклонения, благодаря которому данные распределяются более сбалансированно. Стандартное отклонение определяет, как распределены данные. Чем больше виртуальных узлов,
тем меньше отклонение. Но при этом нужно больше места для хранения данных о виртуальных узлах. Мы можем подобрать такое количество, которое лучше всего соответствует требованиям нашей системы.

