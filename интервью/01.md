Разделение системы (веб-сервер) на веб-уровень (веб-сервер) и уровень данных (БД) позволяет *масштабировать* эти компоненты независимо друг от друга.

**Реляционные БД** (MySQL, Oracle, PostgreSQL и т. д.) предоставляют и хранят данные в таблицах и строках. С помощью SQL можно выполнять операции объединения между различными таблицами базы данных.

**Нереляционные БД** также называют *NoSQL* (CouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB и т. д.). Эти базы данных делятся на четыре категории: хранилища «ключ–значение», графовые, столбцовые и документные. Нереляционные БД обычно неподдерживают операции соединения. Нереляционные БД могут быть подходящим решением, если:
  - ваше приложение нуждается в крайне низкой латентности (**Latency** - это время ожидания, которое требуется на доставку пакета данных от источника к пункту назначения.);
  - ваши данные не структурированы или не имеют никаких реляционных связей;
  - вам нужно лишь сериализовать и десериализовать свои данные(JSON, XML, YAML и т. д.). *Сериализация и десериализация* - это процессы преобразования данных из одной формы в другую с целью сохранения или передачи информации.;
  - вам нужно хранить огромные объемы данных.

**Вертикальное масштабирование**, известное как наращивание, — это процесс повышения мощности ваших серверов (процессоров, памяти оперативной или дисковой и т. д.). Вертикальное масштабирование отлично подходит для задач с небольшим трафиком. Его главным преимуществом является простота (добавить несколько планок RAM просто). Но есть ряд серьезных ограничений:
  - Вертикальное масштабирование имеет жесткий лимит. Ресурсы отдельно взятого сервера нельзя увеличивать бесконечно.
  - Вертикальное масштабирование не предусматривает отказоустойчивость и резервирование избыточных ресурсов. Если один из серверов выйдет из строя, веб-сайт/приложение станет полностью недоступным.
    
**Горизонтальное масштабирование**, которое еще называют расширением, заключается в добавлении новых серверов в пул ресурсов. Лучше подходит для крупномасштабных приложений.

**Балансировщик нагрузки** равномерно распределяет входящий трафик между веб-серверами (чтобы один сервер не вышел из строя после внезамно возросшей нагрузки от большого кол-ва пользователей). Те запросы от пользователей идут на IP-адрес балансировщика нагрузки (который был получен от DSN сервера). По соображениям безопасности для взаимодействия между серверами используются внутренние IP-адреса. Внутренний IP доступен только для серверов из той же *сети*, но не виден из интернета. Балансировщик нагрузки взаимодействует с веб-серверами с помощью внутренних IP-адресов. За счет добавления балансировщика нагрузки и второго сервера нам удается решить проблему с отсутствием отказоустойчивости и улучшить доступность веб-уровня. Т.е.:
 - Если сервер 1 выходит из строя, весь трафик перенаправляется к серверу 2. Благодаря этому веб-сайт остается доступным. Чтобы сбалансировать нагрузку, мы добавим в пул серверов новый исправный веб-сервер.
 - Если посещаемость веб-сайта стремительно растет и для обслуживания трафика не хватает двух серверов, балансировщик нагрузки может изящно справиться с этой проблемой. Для этого достаточно расширить пул серверов, и балансировщик начнет автоматически
передавать запросы новым веб-серверам.

**Репликая** - те создание копии БД, решает проблему отказоустойчивости и резервирования для уровня БД. Репликация баз данных обычно используется в режиме "ведущий–ведомый", где роль ведущего сервера играет оригинал (master), а его копии являются ведомыми (slave). Ведущая база данных обычно поддерживает только операции записи. Ведомые БД получают от ведущей копии ее содержимого и поддерживают только операции чтения (если ведомая БД только одна - то после её падения операции чтения перенаправятся на ведущую, если же более одной - то перенаправятся на остальным ведомые). Если ведущая база данных выйдет из строя, ее место (временно) займет одна из ведомых.
Все команды для модификации данных, такие как *вставка*, *удаление* или *обновление*, должны направляться ведущей базе данных. В большинстве приложений чтение происходит намного чаще, чем запись, поэтому ведомых БД обычно больше, чем ведущих. Преимущества репликации базы данных:
  - Повышенная производительность. В модели «ведущий–ведомый» все операции записи и обновления происходят на ведущих узлах, а операции чтения распределяются между ведомыми. Это улучшает производительность, увеличивая количество запросов, которые можно обрабатывать параллельно.
  - Надежность. Если один из ваших серверов с базой данных сломается из-за стихийного бедствия, такого как тайфун или землетрясение, данные не будут утеряны. Вам не нужно беспокоиться о потере данных, так как они реплицируются по разным местам.
  - Высокая доступность. За счет репликации данных по разным местам ваш веб-сайт будет продолжать работать, даже если одна из БД вый­дет из строя, поскольку у вас по-прежнему будет доступ к данным, размещенным на другом сервере.

**Кэш** — это участок памяти (оперативной, те быстрой), в который временно записываются результаты ресурсоемких ответов или данных, к которым часто обращаются. Это позволяет ускорить обслуживание последующих запросов (тк многократное обращение к БД существенно влияет на производительность в худшую сторону). Преимущество отдельного кэша - это возможность масштабировать его. Если данные есть в кэше, читаем их из кэша, если данных нет в кэше - читаем из БД и сохраняем их в кэш. Эта стратегия называется *кэшем сквозного чтения*.

Некоторые аспекты использования кэша:
  - Определитесь с тем, когда будет использоваться кэш. Это лучше делать в ситуациях, когда чтение данных происходит часто, а изменение — редко. Поскольку кэшированные данные хранятся в энергозависимой памяти, сервер кеширования не подходит для постоянного хранения. Например, если он перезапустится, все данные, хранившиеся в памяти, будут утрачены. В связи с этим данные необходимо записывать в постоянные хранилища.
  - Выбор срока действия. Рекомендуется реализовать механизм, ограничивающий срок действия кэша. Просроченные данные немедленно удаляются. Если такого механизма нет, данные будут храниться в памяти постоянно. Срок действия лучше не делать слишком коротким, иначе система будет слишком часто обновлять данные, загружая их из БД. С другой стороны, из-за слишком длинного срока действия данные могут оказаться неактуальными.
  - Согласованность. Это подразумевает синхронизацию данных в хранилище и кэше. Несогласованность может возникнуть из-за того, что операции изменения данных в хранилище и кэше выполняются не за одну транзакцию. При масштабировании системы в пределах нескольких регионов может быть непросто поддерживать согласованность.
  - Предотвращение сбоев. Наличие лишь одного сервера кэширования может оказаться потенциальной единой точкой отказа (single point of failure, SPOF), которая, согласно английской Википедии, имеет следующее определение: «Единая точка отказа — это компонент, выход из строя которого приводит к прекращению работы всей системы». В связи с этим, чтобы избежать SPOF, рекомендуется использовать несколько серверов кэширования, размещенных в разных центрах обработки данных (ЦОД). А еще можно выделить какой-нибудь дополнительный объем памяти: это создаст буфер на случай, если память начнет использоваться более активно. 
  - Политика вытеснения. Когда кэш полностью заполнен, любой запрос на добавление новых элементов может привести к удалению существующих. Это называют вытеснением кэша. Самой по­пулярной политикой считается вытеснение давно неиспользуемых данных (least-recently-used, LRU). Для разных ситуаций могут также подойти вытеснение наименее часто используемых данных (least-frequently-used, LFU) или метод «первым пришел, первым ушел» (FIFO, first-in-first-out).

**CDN** — это сеть географически распределенных серверов, которая используется для доставки статического содержимого. Серверы CDN кэшируют такие статические файлы, как изображения, видео, CSS, JavaScript и т. д. Принцип работы - когда пользователь посещает веб-сайт, ближайший к нему сервер CDN доставляет статическое содержимое (файл), но если в кэше сервера CDN нет запрашиваемого файла он запрашивает этот файл
из оригинального источника, например веб-сервера или онлайн-хранилища вроде Amazon S3 (или др. S3-подобного). Источник (веб-сервера или онлайн-хранилища) возвращает серверу CDN файл вместе с дополнительным HTTP-заголовком TTL (Time-to-Live — «время жизни»), который определяет, как долго изображение будет находиться в кэше. CDN кэширует файл и возвращает его пользователю. Оно остается в кэше CDN, пока не истечет срок TTL. При повтороном обращени к файлу - если срок TTL еще не истек, изображение возвращается из кэша.

Нюансы использования CDN:
  - Стоимость. Серверы CDN предоставляются сторонними компаниями, а перемещение данных в CDN и из CDN стоит денег. Кэширование нечасто используемых ресурсов не даст существенных преимуществ, поэтому из CDN их лучше убрать.
  - Подбор подходящего срока годности кэша. Для содержимого, которое зависит от времени, необходимо предусмотреть срок годности кэша. Он должен быть не слишком длинным, но и не слишком коротким. В первом случае содержимое может потерять свою актуальность, а во втором — привести к повторной перезагрузке содержимого с исходных серверов в CDN.
  - Возможность сбоев. Вы должны подумать о том, как ваши веб-сайты/приложения будут справляться с недоступностью CDN. Если CDN временно выходит из строя, у клиента должна быть возможность обнаружить эту проблему и запросить ресурсы из исходного источника.
  - Аннулирование файлов. Файлы можно удалять из CDN до истечения их срока годности одним из следующих способов:
    - аннулировать объект CDN с помощью API-интерфейсов, предоставляемых поставщиками CDN;
    - использовать версионирование, чтобы возвращать разные версии объектов. Для этого к URL-адресу можно добавить параметр с номером версии. Например, версия 2 может быть представлена строкой запроса: image.png?v=2.

Для *горизонтального масштабирования* веб-уровня (веб-сервиса, веб-сервер). Для этого нужно вынести из него состояние, те stateless (например, информацию о пользовательских сеансах).  Данные сеансов рекомендуется записывать в постоянные хранилища, такие как реляционные БД или NoSQL. Каждый веб-сервер в кластере может запросить состояние из БД. Отсутствие состояния делает систему более простой, надежной и масштабируемой.

От того, хранит сервер состояние или нет, зависит, будет ли он «помнить» данные клиента (состояние) между разными запросами. Чтобы пользователь попадал именно на тот сервер, на котором хранятся его данные сеанса - балансировщик нагрузки должен всегда перенапралвять его на один и тот же сервер (бу алансировщиков нагрузки для этого предусмотрены *липкие сеансы*) иначе пользователь будет не аутентифицирован (те распознан, тк данных о нём на этом сервере нет).

Подход *липкие сеансы*  увеличивает накладные расходы. Из-за него добавление и удаление серверов дается с трудом. Также возникают проблемы, если сервер выходит из строя.

***Автомасштабирование** означает, что добавление и удаление веб-серверов происходит автоматически в зависимости от объемов трафика за счет добавления и удаления серверов с учетом нагрузки.

**ЦЕНТРЫ ОБРАБОТКИ ДАННЫХ** (ЦОД) - используются для улучшения *доступности* и *UX*, их должно быть несколько. Те с помощью GeoDNS направляются к ближайшему центру обработки данных. В случае любого серьезного нарушения работы одного из центров обработки данных мы перенаправляем весь трафик к исправному ЦОД.

**UX** расшифровывается как *user experience* ― «пользовательский опыт». Это то, каким образом пользователь взаимодействует с интерфейсом и насколько сайт или приложение для него удобны.

**GeoDNS** (система географических доменных имен) - это процесс распределения трафика на основе местоположения запросов. Его также называют *директором трафика* или *директором глобального трафика*. Используя сервис GeoDNS, вы можете эффективно оптимизировать трафик к доменам за счет использования географической маршрутизации.

Для реализации архитектуры с несколькими центрами обработки данных необходимо решить несколько технических вопросов:
  - Перенаправление трафика. Необходимы эффективные инструменты для направления трафика к подходящему ЦОД. GeoDNS позволяет выбирать центр обработки данных, который находится ближе всего к пользователю.
  - Синхронизация данных. Пользователи могут работать с разными локальными базами данных и кэшами в зависимости от региона. В случае сбоя трафик может быть перенаправлен к ЦОД, в котором нет запрашиваемых данных. Распространенным решением является репликация данных между несколькими ЦОД.
  - Тесты и развертывание. В конфигурации с несколькими ЦОД тестирование веб-сайта/приложения необходимо проводить в разных местах. Автоматические средства развертывания незаменимы в поддержании согласованности всех ЦОД.

Чтобы еще сильнее улучшить масштабируемость системы, ее следует разделить на компоненты; это позволит масштабировать их независимо друг от друга, а для взаимодействия этих компонентов в распределенных системах хорошо подходят очереди сообщений.

**Очередь сообщений** — это устойчивый компонент, который загружается в память и поддерживает асинхронное взаимодействие. Он служит буфером и распределяет асинхронные запросы. Очередь сообщений имеет
простую базовую архитектуру. Сервисы ввода, так называемые производители/издатели, создают сообщения и публикуют их в очереди. Другие сервисы или серверы, которые называют потребителями/подписчиками,
подключаются к очереди, читаю сообщения и выполняют действия, определенные в этих сообщениях. Очередь сообщений помогает сделать систему менее связанной и более устойчивой к отказам.

Благодаря разделению очередь сообщений является предпочтительной архитектурой для создания *масштабируемых* и *надежных* приложений. Производитель может публиковать сообщения в очереди, даже если
потребитель не в состоянии их обработать. И наоборот — потребитель может считывать сообщения из очереди, даже если производитель недоступен. Производитель и потребитель могут масштабироваться независимо друг от друга. Когда очередь становится слишком большой, для сокращения времени обработки добавляются новые рабочие узлы. Если же очередь в основном пустует, количество рабочих узлов можно уменьшить.

**Логирование**. Мониторинг логов играет важную роль, помогая выявлять в системе *ошибки* и *проблемы*. Логи можно отслеживать на каждом отдельном сервере, но есть также инструменты, позволяющие собирать их
в централизованном сервисе ради *удобства поиска* и *просмотра*.

**Метрики**. Сбор разного рода метрик помогает лучше понять предметную область и оценить работоспособность системы. Вам может пригодиться что-то из следующего:
  - метрики уровня сервера: процессор, память, дисковый ввод/вывод и т. д.;
  - агрегированные метрики: производительность всего уровня базы данных, уровня кэша и т. д.;
  - ключевые бизнес-метрики: суточное количество активных пользователей, удержание, доход и т. д.

**Автоматизация**. Когда система становится большой и сложной, для повышения продуктивности необходимо разработать новые или использовать уже готовые средства автоматизации. Рекомендуется применять
непрерывную интеграцию — это когда каждая фиксация кода автоматически проверяется, что помогает обнаруживать проблемы на ранних этапах. Кроме того, автоматизация процессов сборки, тестирования,
развертывания и других может существенно повысить продуктивность разработчиков.

Есть два общих подхода к масштабированию БД: **вертикальный** и **горизонтальный**.

**Вертикальное масштабирование** (или наращивание) подразумевает повышение производительности существующего компьютера за счет добавления ресурсов процессора, памяти, диска и т. д. Серверы баз данных бывают довольно мощными. У вертикального масштабирования есть серьезные недостатки:
  - Можно добавлять к своему серверу дополнительные ресурсы процессора, памяти и т. д., но аппаратные ограничения игнорировать не получится. Если у вас много пользователей, одного сервера будет недостаточно.
  - Повышенный риск возникновения единой точки отказа.
  - Вертикальное масштабирование имеет высокую общую стоимость. Мощные серверы очень дорогие.

**Горизонтальное масштабирование** (или расширение) заключается в добавлении новых серверов. 

**Шардинг** позволяет разделить крупные наборы данных на более мелкие и простые в использовании части, которые называют *шардами*. Все шарды имеют одну и ту же схему, но каждый из них хранит уникальные данные (например, при каждом обращении к данным используется функция хеширования, которая находит подходящий шард. Например, функция хеширования имеет вид user_id % 4. Если результат равен 0, для хранения и извлечения данных используется сегмент 0. Если результат равен 1, выбирается сегмент 1.). При реализации стратегии сегментирования самый важный фактор — это выбор ключа. Ключ шардинга (или ключ раздела) состоит из одного или нескольких столбцов, на основе которых происходит распределение данных. Так же, при выборе ключа шардинга один из важнейших критериев — возможность *равномерного* распределения данных. Шардинг отлично подходит для масштабирования баз данных. Но он и усложняет систему, и создает дополнительные трудности:
  - **Повторное сегментирование данных**. Это может понадобиться, когда 1) отдельный шард полностью заполняется из-за стремительного развития системы или 2) некоторые шарды заполняются быстрее других из-за неравномерного распределения данных. В такой ситуации необходимо обновить функцию сегментирования и переместить имеющиеся данные. Для решения этой проблемы зачастую применяют *согласованное хеширование* (о нем позже).
  - Проблема знаменитостей. Слишком частое обращение к определенному шарду может вызвать перегрузку сервера. Представьте, что информация о Криштиану Роналду и Эксле Роузе очутилась в одном и том же сегменте. Если речь идет о социальных приложениях, этот сегмент будет перегружен операциями чтения. Для решения этой проблемы, возможно, придется выделить по отдельному шарду для каждой знаменитости. Может случиться так, что каждый сегмент потребует дальнейшего разделения.
  - **Соединение и денормализация**. После сегментирования базы данных между несколькими серверами становится сложно выполнять операции соединения, охватывающие несколько шардов. Распространенное решение состоит в денормализации базы данных таким образом, чтобы запросы могли выполняться в рамках одной таблицы.

Суммарно шаги, которые предпринимаются в ходе масштабирования системы для поддержки миллионов пользователей:
  - веб-уровень не должен хранить состояния;
  - резервирование должно быть предусмотрено на каждом уровне;
  - кэширование данных следует проводить как можно более активно;
  - система должна поддерживать больше одного центра обработки данных;
  - статические ресурсы нужно хранить в CDN;
  - для масштабирования данных следует применять шардинг;
  - уровни должны быть разделены на отдельные сервисы;
  - необходимо выполнять мониторинг системы и использовать средства автоматизации.


Продолжительности типичных компьютерных операций (некоторые из этих показателей потеряли актуальность в связи с повышением производительности компьютеров):
  - Обращение к кэшу L1: 0,5 нс (наносекунда)
  - Ошибочное предсказание перехода: 5 нс
  - Обращение к кэшу L2: 7 нс
  - Блокирование/разблокирование мьютекса: 100 нс
  - Обращение к основной памяти: 100 нс
  - Сжатие 1 Кб с помощью Zippy: 10 000 нс = 10 мкс (микросекунда)
  - Отправка 2 Кб по сети 1 Гбит/с: 20 000 нс = 20 мкс
  - Последовательное чтение из памяти 1 Мб: 250 000 нс = 250 мкс
  - Перемещение пакета туда и обратно внутри одного ЦОД: 500 000 нс = 500 мкс
  - Время поиска по диску: 10 000 000 нс = 10 мс (миллисекунда)
  - Последовательное чтение 1 Мб из сети: 10 000 000 нс = 10 мс
  - Последовательное чтение 1 Мб с диска: 30 000 000 нс = 30 мс
  - Передача пакета из Калифорнии в Нидерланды и обратно: 150 000 000 нс = 150 мс

**Выводы**: 
  - память быстрая, а диск медленный;
  - по возможности следует избегать поиска по диску;
  - простые алгоритмы сжатия отличаются высокой скоростью;
  - прежде чем отправлять данные по интернету, их по возможности нужно сжимать;
  - центры обработки данных обычно находятся в разных регионах, и передача информации между ними занимает время.

**Высокая доступность** — это способность системы долго и непрерывно находиться в рабочем состоянии. Она измеряется в процентах. 100 % означает, что сервис никогда не простаивает. У большинства сервисов
доступность варьируется от 99 % и 100 %.

**SLA** (service level agreement) - те соглашение об уровне услуг, это соглашение между вами (поставщиком) и вашим клиентом, которое официально определяет уровень беспрерывной работы вашего сервиса. Облачные провайдеры предлагают SLA от 99,9 % и выше (чем больше девяток, тем лучше, например 99,9999 %).

НИЖЕ ПРИМЕР ОЦЕНКИ ТРЕБОВАНИЙ К QPS И ХРАНИЛИЩУ.

Предположения:
  - 300 миллионов активных пользователей в месяц;
  - 50 % из них пользуются сервисом ежедневно;
  - пользователи в среднем публикуют по 2 поста в день;
  - 100 % постов содержат медиаданные;
  - данные хранятся на протяжении 5 лет.

Оценки:
  - ежедневные активные пользователи (daily active users, DAU) = 300 миллионов * 50 % = 150 миллионов;
  - запросов в секунду (queries per second, QPS) = 150 миллионов * 2 поста / 24 часа / 3600 секунд = ~3500 запросов в секунду;
  - пиковый показатель QPS = 2 * QPS = ~7000 запросов в секунду.

Оценка места, необходимого для хранения данных:
  - средний размер поста:
    - post_id — 64 байта;
    - текст — 140 байтов;
    - медиаданные — 1 Мб;
  - объем данных: 150 миллионов * 2 поста * 10% (или 1/10) * 1 Мб = 30 Тб в день;
  - объем данных за 5 лет: 30 Тб * 365 дней в году * 5 лет = ~55 Пб.


 Общие этапы интервью.

1-ы шаг. Понять задачу. Подумайте и задайте правильные вопросы, чтобы уточнить требования и допущения, сделать подходящие предположения и собрать всю информацию, необходимую для создания системы. Так же свои мысли лучше записать. 3–10 минут.
Примеры вопросов:
  - какие именно возможности мы будем реализовывать?
  - сколько пользователей у нашего продукта?
  - как скоро ожидается наращивание мощностей? Какой масштаб планируется через 3 месяца, полгода, год?
  - как выглядит технологический стек компании? Какие существующие сервисы можно применить для упрощения архитектуры?

2-ой шаг. Пытаемся выработать общее решение и получить аппрув от интервьюера. 10–15 минут.
  - Предложите начальный план архитектуры. Поинтересуйтесь мнением интервьюера. Относитесь к нему как к члену своей команды, с которым вы вместе работаете.
  - Нарисуйте на доске блок-схемы (крупноблочно) с ключевыми компонентами, такими как клиенты (мобильные/браузерные), API-интерфейсы, веб-серверы, хранилища данных, кэши, CDN, очереди сообщений и т. д.
  - Выполните приблизительные расчеты, чтобы понять, соответствует ли ваше решение масштабу задачи. Рассуждайте вслух. Прежде чем что-то считать, пообщайтесь с интервьюером.

По возможности пройдитесь по нескольким конкретным сценариям использования. Это поможет вам сформировать общую архитектуру и, скорее всего, обнаружить крайние случаи, о которых вы еще не думали.

3-ий шаг. Глубокое (подробное) погружение в проектирование.  10–25 минут.
Работая совместно с интервьюером, вы должны определить компоненты архитектуры и назначить им тот или иной приоритет. Например, если вы проектируете сервис для сокращения URL-адресов, особый интерес будет представлять функция хеширования, превращающая длинный адрес в короткий. В системе обмена сообщениями двумя интересными аспектами являются снижение латентности и поддержка онлайн/офлайн-статусов.  Старайтесь не углубляться в ненужные подробности.

4-ый шаг. Подведение итогов, вопросы про улучшение, уточняющие вопросы. 3–5 минут.
  - Интервьюер может попросить вас обозначить узкие места системы и обсудить потенциальные улучшения. Всегда можно что-то улучшить. Это отличная возможность продемонстрировать свое критическое мышление.
  - Возможно, стоит провести краткий обзор вашей архитектуры, особенно если вы предложили несколько решений.
  - Будет интересно поговорить о внештатных ситуациях, таких как поломка серверов, разрыв сети и т. д.
  - Стоит затронуть эксплуатационные вопросы. Как вы отслеживаете метрики и журналы ошибок? Как выкатывается система?
  - Проведение следующего этапа масштабирования — тоже весьма интересная тема. Например, если ваша текущая архитектура поддерживает 1 миллион пользователей, какие изменения нужно внести, чтобы увеличить эту цифру до 10 миллионов?
  - Если еще остается время, предложите дальнейшие улучшения.

**Ограничитель трафика** используется в сетевых системах для управления скоростью передачи данных от клиента или сервиса. В мире HTTP он ограничивает количество запросов, которые пользователь может отправить за определенный промежуток времени. Если исчерпано максимальное число API-запросов, заданное ограничителем трафика, все последующие вызовы блокируются. 

Вот несколько примеров:
  - пользователь может создать не больше двух сообщений в секунду;
  - с одного IP-адреса можно создать не больше 10 учетных записей в день;
  - на одном устройстве можно получить не больше 5 наград в неделю.

Преимущества использования компонента "Ограничитель трафика" в API:
  - Предотвращение нехватки ресурсов, вызванной DoS-атакой (Denial of Service — «отказ в обслуживании»). Ограничитель трафика предотвращает как спланированные, так и непредумышленные DoS-атаки, блокируя избыточные вызовы.
  - Экономия бюджета. Ограничение избыточных запросов позволяет освободить часть серверов и выделить больше ресурсов для высокоприоритетных API. Это чрезвычайно важно для компаний, которые используют платные сторонние API. Например, вам может стоить
денег каждое обращение к внешним API, которые позволяют проверить кредитные средства, отправить платеж, получить записи медкарты и т. д. Ограничение количества вызовов играет важную роль в снижении расходов.
  - Предотвращение перегрузки серверов. Чтобы снизить нагрузку на серверы, ограничитель трафика фильтрует лишние запросы, исходящие от ботов или недобросовестных пользователей.

Ограничение трафика можно реализовать с помощью разных алгоритмов, каждый из которых имеет как преимущества, так и недостатки. Он может быть релизован на клиентской стороне или серверной те на стороне API.

**Алгоритм маркерной корзины** (token bucket) работает следующим образом:

  - Маркерная корзина — это контейнер с заранее определенной емкостью (размер корзины). В нее регулярно помещают маркеры/житоны. Когда она окончательно заполняется, маркеры больше не добавляются (последующие маркеры отбрасываются).
  - Затем с интервалом в минуту (частота пополнения) - добавляем маркеров до полной корзины (до размера корзины). Те по сути, если ёмкость равна 4 - мы ограничиваем максимум 4 запроса в минуту.

Сколько корзин нам нужно? Примеры:

  - Для разных конечных точек API обычно нужны разные корзины. Например, если пользователь публикует 1 сообщение в секунду, добавляет 150 друзей в день и «лайкает» 5 сообщений в секунду, каждому пользователю нужно выделить 3 корзины.
  - Если нам нужно фильтровать запросы в зависимости от IP-адресов, каждому IP-адресу требуется корзина.
  - Если система допускает не больше 10 000 запросов в секунду, логично предусмотреть глобальную корзину для всех запросов.

Преимущества:
  - легкая реализация;
  - эффективное потребление памяти;
  - маркерная корзина может справиться с короткими всплесками трафика; пока в корзине остаются маркеры, запрос обрабатывается.

Недостатки:
  - несмотря на то что алгоритм принимает лишь два параметра (размер корзины и частота пополнения), подобрать подходящие значения может быть непросто.


**Алгоритм дырявого ведра** (leaking bucket) - первый обрабатывает запросы с фиксированной скоростью (обычно по принципу FIFO). Работает следующим образом:
  
  - при поступлении запроса система проверяет, заполнена ли очередь. Запрос добавляется в очередь при наличии места;
  - в противном случае запрос отклоняется;
  - запросы извлекаются из очереди и обрабатываются через равные промежутки времени.

Алгоритм дырявого ведра принимает два параметра:
  - размер ведра: равен размеру очереди; очередь хранит запросы, которые обрабатываются с постоянной скоростью;
  - скорость утечки: определяет, сколько запросов можно обработать за определенный промежуток времени (обычно за 1 секунду).

Преимущества:
  - эффективное потребление памяти при ограниченном размере очереди;
  - запросы обрабатываются с постоянной скоростью, поэтому этот алгоритм подходит для задач, которые требуют стабильной скорости обработки.

Недостатки:
  - всплеск трафика наполняет очередь старыми запросами, и, если их вовремя не обработать, новые запросы будут отклоняться;
  - несмотря на то что алгоритм принимает лишь два параметра, подобрать подходящие значения может быть непросто.

**Счетчик фиксированных интервалов** (fixed window counter). Работает следующим образом:
  - Алгоритм делит заданный период времени на одинаковые интервалы и назначает каждому из них счетчик.
  - Каждый запрос инкрементирует счетчик на 1.
  - Как только счетчик достигнет заранее заданного лимита, новые запросы начинают отклоняться, пока не начнется следующий интервал.

Преимущества:
  - эффективное потребление памяти;
  - понятность;
  - сброс квоты доступных запросов в конце временного интервала подходит для ряда задач.

Недостатки:
  - всплески трафика на границе временных интервалов могут привести к приему запросов, количество которых превышает квоту.

**Журнал скользящих интервалов** (sliding window log). Работает следующим образом:
  - Алгоритм следит за временными метками запросов. Временные метки обычно хранятся в кэше, например, в упорядоченных множествах Redis
  - Когда поступает новый запрос, все просроченные запросы отбрасываются. Просроченными считают запросы раньше начала текущего временного интервала.
  - Временные метки новых запросов заносятся в журнал.
  - Если количество записей в журнале не превышает допустимое, запрос принимается, а если нет — отклоняется.

Преимущества:
  - ограничение трафика, реализованное с помощью этого алгоритма, получается очень точным; на любом скользящем интервале запросы не превышают заданный лимит.

Недостатки:
  - этот алгоритм потребляет много памяти, потому что даже в случае отклонения запроса соответствующая временная метка записывается в журнал.

**Счетчик скользящих интервалов** (sliding window counter). Счетчик скользящих интервалов — это гибридный подход, сочетающий в себе два предыдущих алгоритма. Его можно реализовать двумя разными способами.

Преимущества:
  - сглаживание всплесков трафика: текущая частота запросов зависит от той, которая использовалась на предыдущем интервале.
  - экономия памяти.

Недостатки:
  - работает только для нежестких ретроспективных интервалов; частота получается приблизительной, так как подразумевается, что запросы на предыдущем интервале распределены равномерно. Но это может быть не настолько серьезной проблемой, как кажется на
первый взгляд.

Правила ограничения трафика  обычно записываются в конфигурационные файлы и сохраняются на диске (например yaml, на рабочих узлах), а промежуточный ограничитель считывает из кэша (значения в кэше обновляют рабочие узлы, сколько запросов в данный момент, временные метки).

Когда запрос отклоняется, API возвращает клиенту HTTP-ответ с кодом 429 («слишком много запросов»). В зависимости от ситуации отклоненные запросы могут быть записаны в очередь, чтобы позже их можно было обработать. Например, если некоторые заказы отклоняются из-за перегруженности системы, мы можем отложить их на потом.

Как клиент узнает, что его трафик ограничивается? И откуда он может узнать количество запросов, которые он может выполнить, прежде чем вступят в силу ограничения? Ответ заключается в заголовках HTTP-ответов. Ограничитель трафика возвращает клиентам следующие HTTP-заголовки:
  - X-Ratelimit-Remaining. Количество допустимых запросов, которое остается в текущем интервале.
  - X-Ratelimit-Limit. Количество вызовов, доступных клиенту в каждом временном интервале.
  - X-Ratelimit-Retry-After. Количество секунд, которое должно пройти, прежде чем ваши запросы престанут отклоняться. Плюс код ошибки 429.


Ограничитель трафика обязательно должен быть распределен по разным центрам обработки данных, ведь чем дальше пользователь находится от ЦОД, тем выше латентность. Данные должны синхронизироваться в соответствии с моделью *отложенной согласованности* (чтобы это не значило).

После реализации ограничителя трафика необходимо собрать аналитические данные, чтобы проверить, насколько он эффективен. Нас в основном интересует эффективность:
  - алгоритма ограничения трафика;
  - правил ограничения трафика.

Если правила ограничения трафика будут слишком строгие - будет теряться много корректных запросов (те нужно будет их ослабить). Ограничитель трафика также может становиться неэффективным во время внезапных всплесков активности, таких как распродажи. Чтобы этого не произошло, можно воспользоваться другим алгоритмом, который лучше справляется с такими условиями. Хорошим вариантом будет алгоритм *маркерной корзины*.

Для обеспечения горизонтального масштабирования запросы/данные должны распределяться между серверами эффективно и равномерно. Для этого зачастую используется *согласованное хеширование*.

Если у вас есть n кэширующих серверов, балансирование нагрузки обычно обеспечивается с помощью следующего метода хеширования: serverIndex = hash(key) % N, где N — размер пула серверов. 
Такой подход работает хорошо, когда пул серверов имеет *фиксированный размер*, а данные распределены равномерно. Но при добавлении новых или удалении существующих серверов возникают проблемы (а именно большинство клиентов начнут извлекать закэшированные данные не из тех серверов, это тн кэш-промахи). Согласованное хеширование — эффективный метод борьбы с этой проблемой.

Согласованное хеширование - вид хеширования, отличающийся тем, что когда хеш-таблица перестраивается (например, когда выходит один из серверов и строя), только K/n ключей в среднем должны быть переназначены, где K — число ключей и n — число слотов (серверов).  В противоположность этому, в большинстве традиционных хеш-таблиц изменение количества слотов вызывает переназначение почти всех ключей.

Алгоритм согласованного хеширования состоит из двух основных этапов:
  - серверы и ключи наносятся на кольцо с использованием равномерно распределенной хеш-функции;
  - чтобы определить, какому серверу принадлежит ключ, нужно пройти по часовой стрелке от позиции ключа к ближайшему серверу на кольце.

У этого подхода есть две проблемы. Первая: учитывая, что серверы могут добавляться и удаляться, их отрезки на кольце не могут иметь фиксированный размер. Отрезок — это пространство хеширования между двумя
соседними серверами. Размер отрезков, назначаемых каждому серверу, может оказаться как очень маленьким, так и достаточно большим. Вторая проблема состоит в том, что распределение ключей на кольце может быть неравномерным. Для решения этих проблем используется методика, известная как *виртуальные узлы* или *реплики*.

Виртуальный узел ссылается на настоящий; каждый сервер представлен на кольце несколькими виртуальными узлами. Благодаря виртуальным узлам каждый сервер отвечает сразу за несколько отрезков. Чтобы узнать, на каком сервере хранится ключ, мы переходим в его позицию на кольце и двигаемся по часовой стрелке к ближайшему виртуальному узлу. Чем больше виртуальных узлов, тем равномернее становится распределение ключей. Это вызвано уменьшением стандартного отклонения, благодаря которому данные распределяются более сбалансированно. Стандартное отклонение определяет, как распределены данные. Чем больше виртуальных узлов,
тем меньше отклонение. Но при этом нужно больше места для хранения данных о виртуальных узлах. Мы можем подобрать такое количество, которое лучше всего соответствует требованиям нашей системы.


При добавлении или удалении сервера часть данных нужно перераспределить. Как определить диапазон затронутых ключей? Когда сервер (s1) удаляется (как показано на рис. 5.15), затронутый диапазон начинается с s1 (удаленного узла) и идет по кольцу против часовой стрелки до ближайшего сервера (s0). Таким образом, ключи, размещенные между s0 и s1, необходимо перенести на s2.

Хранилище типа «ключ–значение» — это нереляционная база данных. Каждый уникальный идентификатор хранится в виде ключа и имеет отдельное значение. В паре «ключ–значение» ключ должен быть уникальным, а соответствующее значение может быть получено через ключ. Ключами могут выступать как обычный текст, так и хешированные значения. Короткие ключи обеспечивают лучшую производительность. Ключ в виде обычного текста: last_logged_in_at; Хешированный ключ: 253DDEC4. Значение в паре может быть строкой, списком, объектом и т. д.

 Хранилище типа «ключ–значение» - очевидное решение заключается в хранении пар в хеш-таблице, содержимое которой находится в памяти. Достать данные оттуда довольно легко, но их объем ограничен из-за лимита
памяти. С этой проблемой можно бороться двумя путями:
  - сжимать данные;
  - хранить в памяти только часто используемые данные, а все остальное записывать на диск.

Но даже с этими мерами отдельно взятый сервер может очень быстро исчерпать свои ресурсы. Для поддержки крупных данных хранилище типа «ключ–значение» должно быть *распределенным*.

Распределенное хранилище типа «ключ–значение» иногда называют распределенной хеш-таблицей. Оно распределяет пары «ключ–значение» между множеством серверов. При проектировании распределенной
системы необходимо понимать теорему CAP (Consistency, Availability, Partition Tolerance — «согласованность, доступность, устойчивость к секционированию»). Одним из этих свойств необходимо пожертвовать,
чтобы обеспечить поддержку двух других.

Теорема **CAP** гласит, что распределенная система может обеспечивать небольше двух из следующих трех свойств: согласованность, доступность и устойчивость к секционированию. Дадим несколько определений:
  - Согласованность. Означает, что все клиенты одновременно видят одни и те же данные, к какому бы узлу они ни подключились. Те каждое чтение с любого узла даст вам самую последнюю запись.
  - Доступность. Означает, что любой клиент, запрашивающий ­данные, получает ответ, даже если некоторые из узлов недоступны. Те каждый узел (не упавший) всегда успешно выполняет запросы (на чтение и запись).
  - Устойчивость к секционированию. Секционирование свидетельствует о нарушении связи между двумя узлами. Устойчивость к секционированию означает, что система продолжает работать вопреки нарушению связи в сети между узлами. Те даже если между узлами нет связи, они продолжают работать независимо друг от друга.


В распределенных системах данные обычно реплицируются больше одного раза (обычно три узла).

В идеальном мире *секционирование сети* не происходит. Данные, записанные в n1, автоматически реплицируются в n2 и n3. Этим достигается как *согласованность*, так и *доступность*.
В распределенной системе разделение неизбежно, и, когда оно происходит, мы должны сделать выбор между *согласованностью* и *доступностью*.

Если узел n3 отказывает (падает) и больше не может взаимодействовать с n1 и n2. Данные, которые клиенты записывают в n1 или n2, не могут дойти до n3. Если же кто-то запишет данные в n3 и они не успеют дойти до n1 и n2, это будет означать, что содержимое n1 и n2 неактуально.

Если мы предпочтем *согласованность* вместо *доступности* (система CP), нам придется заблокировать все операции записи на узлах n1 и n2, чтобы избежать рассинхронизации данных между этими тремя серверами. Этим
мы сделаем систему недоступной. 

Чрезвычайно высокие требования к согласованности обычно имеют банковские системы. Например, для банка крайне важно отобразить самую актуальную информацию о балансе клиента. Если из-за разделения сети произойдет рассинхронизация, банковская система начнет возвращать ошибки, пока проблема не будет устранена.

Если же мы отдадим предпочтение *доступности* перед *согласованностью* (система AP), система продолжит принимать операции чтения, несмотря на то что она может вернуть устаревшие данные. Что касается операций
записи, то они останутся доступными на узлах n1 и n2, а после устранения сетевых неполадок данные будут синхронизированы с n3.

**Секционирование данных**. В крупных приложениях все данные не могут поместиться на одном сервере. Проще всего было бы разделить их на части (секции) меньшего размера и хранить на разных серверах. При сционировании данных необходимо решить две проблемы:
  - равномерно распределить их между разными серверами;
  - минимизировать их перемещение при добавлении или удалении узлов.

В качестве решения отлично подойдет *согласованное хеширование* (где серверы наносятся на кольцо хеширования, затем на том же кольце хешируется ключ, который сохраняется на ближайшем сервере по часовой стрелке). Использование согласованного хеширования для секционирования данных имеет следующие преимущества:
  - **Автоматическое масштабирование**. Серверы можно добавлять и удалять автоматически в зависимости от загрузки.
  - **Гетерогенность**. Количество виртуальных узлов сервера пропорционально его емкости. Например, серверам с большей емкостью назначают больше виртуальных узлов.

**Репликация данных**. Чтобы достичь высокой *доступности* и *надежности*, данные должны асинхронно реплицироваться по N серверам, причем параметр N можно настраивать. Эти N серверов выбираются по такому принципу: после нанесения ключа на кольцо хеширования мы двигаемся по часовой стрелке от его позиции и выбираем ближайшие N серверов для хранения копий данных. Первые N виртуальных узлов могут принадлежать физическим серверам, количество которых меньше N. Чтобы избежать этой проблемы, при прохождении по часовой стрелке выбираются только уникальные (те физические) серверы. Узлы, находящиеся в одном центре обработки данных, зачастую выходят из строя одновременно в результате отключения электричества, неполадок в сети, стихийных бедствий и т. д. Для повышения надежности системы реплики размещаются в разных ЦОД, между которыми установлены высокоскоростные сетевые соединения.


**Согласованность**. Так как данные реплицируются по нескольким узлам, они должны синхронизироваться между репликами. Консенсус кворума может обеспечить согласованность как чтения, так и записи. 
Операция записи считается успешной, только если она подтверждена W репликами. Чтобы операцию записи можно было считать успешной, необходимо дождаться ответа как минимум от R реплик. N = количество реплик.
Выбор значений для W, R и N — это типичный компромисс между латентностью и согласованностью. Если W = 1 или R = 1, операция завершается быстро, так как координатору нужно ждать ответа только от
одной из реплик. Если же W или R больше 1, система становится более согласованной, но при этом координатору придется ждать ответа от самой медленной реплики, что замедлит выполнение запросов. W + R > N гарантирует строгую согласованность, поскольку в системе должен быть как минимум один узел с тем же минимальным набором данных.
Несколько возможных вариантов для конфигурирования N, W и R:
  - если R = 1 и W = N, система оптимизирована для быстрого чтения;
  - если W = 1 и R = N, система оптимизирована для быстрой записи; 
  - если W + R > N, гарантируется строгая согласованность (обычно N = 3, W = R = 2);
  - если W + R <= N, строгая согласованность не гарантируется.

**Модель согласованности** - определяет степень согласованности данных и имеет широкий спектр разновидностей:
  - Строгая согласованность. Любая операция чтения возвращает значение, соответствующее результату самой последней операции записи. Клиент всегда получает актуальные данные.
  - Слабая согласованность. Последующие операции чтения могут и не вернуть самое последнее значение.
  - Согласованность в конечном счете. Это разновидность слабой согласованности. Рано или поздно все обновления распространяются по системе и все реплики становятся согласованными.

*Жесткая согласованность* обычно достигается за счет того, что операции чтения/записи принимаются только после подтверждения текущей записи всеми репликами. Это не самый оптимальный подход для высокодоступных систем, так как он может блокировать новые операции.

*Отложенная согласованность* допускает поступление в систему несогласованных значений, заставляя клиента их прочитать и согласовать.


Репликация обеспечивает высокую доступность, но при этом делает реплики несогласованными. Для решения этой проблемы применяются *версионирование* и *векторные часы*. **Версионирование** — это когда каждое обновление данных приводит к появлению их новой неизменяемой версии. **Векторные часы** — это пара [сервер, версия], связанная с элементом данных. С ее помощью можно проверить, какая из двух версий более новая
и есть ли между ними конфликт.

В любых крупномасштабных системах *сбои* являются не только неизбежным, но и довольно распространенным явлением. 

**Обнаружение сбоев**.  Оптимальное решение состоит в использовании децентрализованных методов обнаружения сбоев, таких как протокол сплетен (gossip protocol). Он работает следующим образом:
  - Каждый узел хранит список узлов-участников, состоящий из идентификаторов и счетчиков пульсации.
  - Каждый узел периодически инкрементирует счетчик пульсации.
  - Каждый узел периодически шлет пульс группе произвольных узлов, которые в свою очередь передают его другой группе.
  - При получении пульса узлы обновляют список участников до последней версии.
  - Если счетчик пульсации не увеличивается на протяжении заранее определенного периода, участник считается недоступным.

**Обработка временных сбоев**. После обнаружения сбоя по протоколу сплетен система должна задействовать определенные механизмы, чтобы обеспечить доступность. Если используется строгий кворум, операции чтения и записи могут быть заблокированы. Для повышения доступности используется методика, известная как нестрогий кворум. Вместо обеспечения кворума система выбирает на кольце хеширования первые W исправных серверов для записи и первые R исправных серверов для чтения. Недоступные серверы игнорируются. Если один сервер недоступен из-за сетевых неполадок, вместо него обработкой запросов временно займется другой. Когда сеть возобновит нормальную работу, изменения будут переданы ранее недоступному серверу, чтобы восстановить согласованность данных. Этот процесс называют *прозрачной* передачей. 

**Обработка бессрочных сбоев**. При падении реплики *безвозвратно* нужно реализовать протокол для предотвращения энтропии, который будет синхронизировать реплики. Это подразумевает сравнение элементов
данных, хранящихся на репликах, и обновление каждой реплики до самой новой версии. Для обнаружения несогласованности и минимизации объема передаваемых данных используется дерево Меркла. Хеш-деревом, деревом Меркла (Merkle tree), называют полное двоичное дерево, в листовые вершины которого помещены хеши от блоков данных, а внутренние вершины содержат хеши от сложения значений в дочерних вершинах. Хеш-деревья обеспечивают эффективную и безопасную проверку содержимого крупных структур данных.


Если ключи находятся в диапазоне от 1 до 12, построить дерево Меркла можно с помощью нескольких шагов:
  - Разделить диапазон ключей на бакеты. Бакет выступает корневым узлом, что позволяет ограничить глубину дерева.
  - После создания бакетов захешировать для каждого из них ключ с помощью одного и того же метода хеширования.
  - Создать по одному хеш-узлу для каждого бакета.
  - Построить дерево снизу вверх до самого корня путем вычисления дочерних хешей.

Сравнение двух деревьев Меркла начинается с их корневых хешей. Если корневые хеши совпадают, серверы содержат одни и те же данные. В противном случае сравниваются дочерние хеши слева направо. В процессе
осмотра дерева мы определяем несогласованные бакеты и синхронизируем только их. При использовании деревьев Меркла количество данных, которые нужно синхронизировать, прямо пропорционально отличиям между двумя
репликами и не зависит от того, сколько всего данных в них хранится. В реальных системах бакеты довольно большие. Например, на один миллион бакетов может приходиться по одному миллиарду ключей — то есть
1000 ключей в каждом бакете.

**Обработка неполадок уровня ЦОД**. Неполадки уровня ЦОД могут быть вызваны отключениями электричества, разрывами сети, стихийными бедствиями и т. д. Чтобы создать систему, способную с ними справиться, данные необходимо реплицировать по нескольким ЦОД. Даже если один ЦОД станет полностью недоступным, пользователи по-прежнему смогут получить данные из других центров обработки.

Подход с использованием первичного ключа с атрибутом auto_increment не работает в распределенных окружениях, так как отдельно взятый сервер БД слишком мал.

Генерировать уникальные ID в рамках нескольких БД с минимальными задержками не так уж просто.

Существуют разные методы генерации уникальных ID в распределенных системах. Рассмотрели следующие варианты:
  - репликация с несколькими источниками;
  - универсальный уникальный идентификатор (universally unique identifier, UUID);
  - сервер тикетов;
  - Twitter snowflake ID — подход «снежного кома» Twitter;

**Репликация с несколькими источниками**. Здесь используется свойство баз данных auto_increment. ID увеличивается не на 1, а на число k, равное количеству используемых БД. Например, есть две БД одна начинает инкрементн на 2 с id = 1, те 1, 3, 5. А вторая начинает инкремент с 2, те 2, 4, 6. Это позволяет избежать определенных проблем с масштабированием, так как идентификаторы могут увеличиваться вместе с количеством серверов БД. Однако у этой стратегии есть серьезные недостатки:
  - сложность масштабирования в конфигурации с несколькими центрами обработки данных;
  - ID не увеличиваются хронологически в пределах нескольких серверов;
  - плохая масштабируемость при добавлении или удалении сервера.

**Универсальный уникальный идентификатор (universally unique identifier, UUID)**. UUID — это 128-битное число, которое используется для идентификации данных в компьютерных системах. UUID имеют очень низкую вероятность повторения. UUID может выглядеть как 09c93e62-50b4-468d-bf8a-c07e1040bfb2. Эти идентификаторы можно генерировать независимо друг от друга без координации между серверами.

Преимущества:
  - простота генерации. Не нужно никакой координации между серверами, что исключает проблемы с синхронизацией;
  - систему легко масштабировать, так как каждый сервер отвечает загенерацию идентификаторов, которые он потребляет. Генератор может легко масштабироваться вместе с веб-серверами.

Недостатки:
  - ID имеют длину 128 бит, а нам нужно 64 бита;
  - ID не увеличиваются со временем;
  - ID могут быть нечисловыми.

**Сервер тикетов (или сервер билетов)**. Суть в том, что мы используем функцию auto_increment в отдельно взятом сервере баз данных (сервере тикетов). 

Преимущества:
  - числовые ID;
  - этот метод легко реализовать, и он подходит для небольших и средних приложений.

Недостатки:
  - Единая точка отказа. Сервер тикетов существует в единственном экземпляре, и если он выйдет из строя, проблемы возникнут у всех систем, которые на него полагаются. Чтобы этого избежать, можно
предусмотреть несколько серверов тикетов, но это вызовет новые трудности, такие как синхронизация данных.

**Twitter snowflake ID (снежный ком)**. Разделяй и властвуй. Вместо того чтобы генерировать идентификатор напрямую, мы разделяем его на части.

1 бит   |     41 бит   |      5 бит   |    5 бит       |        12 бит

 0   |   временная метка  |  ID ЦОД  | ID компьютера |  номер последовательности

Каждая часть описана ниже:
  - Бит знака: 1 бит. Всегда равен 0 и зарезервирован на будущее. С его помощью потенциально можно различать знаковые и беззнаковые числа.
  - Временная метка: 41 бит. Количество миллисекунд, прошедших с начала эпохи Unix или какого-то другого момента. В Twitter snowflake начальной точкой по умолчанию является Ноя 04, 2010, 01:42:54 UTC,
что эквивалентно 1288834974657.
  - ID ЦОД: 5 бит, что дает нам 2 ^ 5 = 32 центра обработки данных.
  - ID компьютера: 5 бит, что дает нам 2 ^ 5 = 32 компьютера в каждом ЦОД.
  - Номер последовательности: 12 бит. При генерации каждого ID на отдельно взятом компьютере или процессе номер последовательности инкрементируется на 1. Каждую миллисекунду этот номер обнуляется.


ID центра обработки данных и ID компьютера выбираются в момент запуска системы и обычно не меняются во время выполнения. Любые обновления этих идентификаторов требуют тщательного анализа, так как неосторожное внесение изменений может привести к конфликтам. Временные метки и номера последовательностей генерируются в ходе работы системы.

*Временная метка*. Поскольку метки увеличиваются со временем, ID можно сортировать в хронологическом порядке.  Можно преобразовать двоичное представления в UTC и обратно.  00100010101001011010011011000101101011000 -> 297616116568 (в десятичной системе). Добалвяем к этомму эпоха Twitter 1288834974657 (те кол-во секунд с Ноя 04, 2010, 01:42:54 UTC). Получем миллисекунды 1586451091225 и переводим их в UTC -> Апр 09 2020 16:51:31UTC

Максимальная временная метка, которую можно представить с помощью 41 бита, равна (2 ^ 41) - 1 = 2199023255551 миллисекундам (мс), что дает нам ~69 лет = 2199023255551 мс / 1000 / 365 дней / 24 часов / 3600 cекунд. Это означает, что этот генератор ID будет работать на протяжении 69 лет, и чем ближе начало эпохи к текущей дате, тем позже произойдет переполнение (те можно выбрать не 4 ноября 2010, а временную точку ближе к старту систему). По прошествии этого времени нужно будет установить новую эпоху или внедрить другой метод для миграции идентификаторов.

*Номер последовательности*. Номер последовательности занимает 12 бит, что дает нам 2 ^ 12 = 4096 комбинаций. Это поле не равно нулю только в случае, если на одном и том же сервере с одну миллисекунду сгенерировано больше одного ID. Теоретически компьютер может генерировать до 4096 новых ID в миллисекунду.

**Перенаправление 301**. Код состояния 301 означает, что запрошенный URL-адрес «навсегда» перемещен по длинному URL-адресу. Так как перенаправление постоянное, браузер кэширует ответ и последующие запросы по тому же адресу не будут направляться к нашему сервису. Вместо этого браузер сразу откроет сокращенный URL-адрес.

**Перенаправление 302**. Код состояния 302 означает, что URL-адрес «временно» перемещен по длинному URL-адресу. То есть последующие запросы того же URL-адреса будут сначала отправляться нашему сервису, а затем перенаправляться к серверу длинного URL-адреса.

У обоих методов перенаправления есть свои плюсы и минусы. Если нам в первую очередь нужно снизить нагрузку на сервер, лучше использовать код состояния 301, так как для каждого сокращенного URL-адреса сервис
будет получать только первый запрос. Если же нам нужна аналитическая информация, стоит выбрать код состояния 302, так как он упрощает отслеживание частоты и источника переходов по ссылке.

Самый очевидный способ реализации перенаправления URL-адресов заключается в использовании *хеш-таблиц*. Но в реальных системах такой подход непрактичен, поскольку ресурсы памяти ограничены и дороги.


Хэш состоит из символов [0-9, a-z, A-Z], число которых равно 10 + 26 + 26 = 62. Чтобы определить длину hashValue, нужно найти наименьшее n, при котором 62^n ≥ 365 миллиардов. Судя по этим прикидкам, система
должна поддерживать до 365 миллиардов URL-адресов. 3,5 триллиона (когда n = 62 ^ 7) более чем достаточно для хранения 365 миллиардов URL-адресов, поэтому длина hashValue будет равна 7.

**Хеш + разрешение конфликтов** (вид функции хеширования). Чтобы сократить длинный URL-адрес, нужно реализовать хеш-функцию, которая хеширует его в строку из 7 символов. Очевидное решение состоит в использовании общеизвестных функций хеширования вроде CRC32, MD5 или SHA-1. Примеры: CRC32: 5cb54054, MD5: 5a62509a84df9ee03fe1230b9df8b84e, SHA-1: 0eeae7916c06853901d9ccbefbfcaf4de57ed85b. Даже самое короткое значение хеша (из CRC32) получается слишком большим (больше 7 символов). Как его сократить? В качестве одного из решений можно взять первые 7 символов хеша, но это чревато конфликтами. Чтобы значения хеша не дублировались, мы можем рекурсивно добавлять к ним заданную строку, пока они не станут уникальными. Начало -> Ввод: longURL -> Хеш-функция -> shortURL -> Если сущ. в БД -> longURL + строка соли и снова на этап Ввод: longURL -> Если не существует -> Сохранить в ДБ -> Конец. Этот метод может избавить нас от конфликтов, но обращаться к базе данных при каждом запросе, чтобы проверить наличие в ней shortURL, довольно расточительно.  Для улучшения производительности можно использовать фильтр Блума . Это вероятностная методика с эффективным использованием пространства, которая позволяет проверить,
входит ли элемент в множество. Напомним, что фильтр Блума позволяет эффективно определить, в какой из таблиц SSTable может находиться ключ.

 **Преобразование base62** (вид функции хеширования). Как понятно из названия, base62 — это способ кодирования с использованием 62 символов. Они соотносятся как 0-0, ..., 9-9, 10-a, 11-b, ..., 35-z, 36-A, …, 61-Z, где «a» соответствует 10, «Z» соответствует 61 и т. д. Те десятичное число 11157 переведем в вид с основанием 62 = 1115710 = 2 x 62^2 + 55 x 62^1 + 59 x 62^0 = [2, 55, 59] -> [2, T, X] в пред-
ставлении base62.

Не стоит отправлять веб-сайту слишком много запросов за короткий промежуток времени (это может быть воспринято как DoS-атака).

Диск медленный (можно хранить буфер в озу и периодически сбрасываеть данные из него на диск.), оперативная память быстрая, но ограничена в обьеме и дорогая.

Для сравнения контекта (дубль или нет) можно использовать хеши или контрольные суммы.

Для ссылок с бесконечно глубокую структуру директорий foo/bar/foo/bar/foo/bar/… можно установать ограничение по длине URL (например 250 символов).

Виды уведомлений: мобильные push-уведомления, SMS, электронные письма.

Отправка **push-уведомлений для iOS** требует наличия трех основных компонентов (Провайдер -> APN -> Устройство iOS):
  - *Провайдер*. Провайдер формирует и отправляет запрос сервису APN (Apple Push Notification). Для создания уведомления он использует следующие данные:
     -  маркер устройства — уникальный идентификатор, который используется для отправки push-уведомлений;
     -  полезные данные — словарь JSON с содержимым уведомления, например: {"aps":{"alert":{"title": "Game Request","body":"Bob wants to play chess","action-loc-key":"PLAY"},"badge":5}}

  - *APN* — удаленный сервис, предоставляемый компанией Apple для доставки push-уведомлений на устройства iOS.
  - *Устройство iOS* — конечный клиент, который получает push-уведомления.

Для отправки **уведомлений устройствам Android** используется похожий механизм, но вместо APN обычно применяется сервис FCM (Firebase Cloud Messaging).


Для рассылки SMS-сообщений обычно используются такие сторонние сервисы, как Twilio, Nexmo  и многие другие. Большинство из них являются коммерческими.

**Электронные письма**. Обычно у компаний есть возможность сконфигурировать собственные почтовые серверы, но многие из них отдают предпочтение коммерческим сервисам. Sendgrid и Mailchimp — одни из самых популярных; они обеспечивают повышенную скорость доставки и включают системы анализа данных.

Нам нужно собрать контактную информация о пользователе (e-mail, телефон). Обычно при установке нашего приложения или во время регистрации пользователь предоставляет такую контактную информацию, которую серверы API сохраняют в базе данных.

Не допускать при проектировании единой точки отказа. Выносить базы данных и кэш (всегда перед базой) за пределы сервера (чтобы мастабировать их). Настраивать автоматическое горизонтальное масштабирование (кубер). Очереди сообщений (kafka) помогают разделить компоненты системы и делаю систему асинхронной, не заставляют ждать.

**Очереди сообщений** позволяют избавиться от зависимостей между компонентами и играют роль буферов, когда отправляется большой объем уведомлений. Каждому типу уведомлений назначается отдельная очередь, чтобы отказ одного стороннего сервиса не сказывался на отправке уведомлений других типов.

Как предотвратить потерю данных? Для этого система записывает уведомления в лог, который хранится в базе данных, и реализует механизм повторных вызовов. 

Доходят ли уведомления до получателя строго в единственном экземпляре? В большинстве случаев уведомление приходит ровно один раз, но из-за *распределенной природы* нашей системы порой случается дублирование. Чтобы это происходило реже, мы используем механизм устранения дубликатов и тщательно обрабатываем каждый неудачный случай. При поступлении события об уведомлении мы сначала проверяем его ID, чтобы узнать, приходило ли оно раньше. Если мы его уже встречали, оно отклоняется. В противном случае мы его отправляем.

Уведомление, которое не удается отправить стороннему сервису, добавляется в очередь сообщений для повторной попытки. 

В приложениях для iOS и Android защита API-интерфейсов push-уведомлений основана на appKey и appSecret. Отправлять push-уведомления с помощью этих API-интерфейсов могут только аутен­тифицированные или проверенные клиенты.

**Мониторинг отложенных уведомлений**. Одной из ключевых метрик мониторинга является общее число ожидающих уведомлений. Если оно становится большим, это означает, что рабочие узлы не успевают обрабатывать события об уведомлениях. Чтобы не задерживать доставку уведомлений, нужно добавить больше рабочих узлов. 

**Отслеживание событий**. Чтобы лучше понимать поведение пользователей, необходимо отслеживать такие метрики, как процент открытия уведомлений, процент кликов и вовлеченность. Отслеживание событий реализует аналитический сервис, который обычно должен быть интегрирован в систему уведомлений.

Лента новостей  (feed) — это постоянно обновляемый список историй в центральной части вашей домашней страницы. Она включает обновления информации о состоянии, фотографии, видео, ссылки, активность приложений и лайки, приходящие от людей, страниц и групп, на которые вы подписаны.

Извлекать идентификаторы друзей удобно из графовой базы данных. Графовая БД подходит для управления связями между друзьями и рекомендации новых друзей. 

*Медиаконтент* (изображения, видео и т. д.) хранится в CDN, чтобы его можно было быстро извлекать (запросы идут на DNS а затем сразу из браузера к ближайшему географически CDN).

Когда клиент хочет начать общение, он соединяется с сервисом чата, используя *один или несколько сетевых протоколов*. Для сервиса чата ­выбор протокола имеет значение. В большинстве клиент-серверных приложений запросы инициируются клиентом.  для передачи сообщения отправитель использует проверенный временем протокол HTTP, который чаще всего встречается в интернете. В этом случае клиент открывает HTTP-соединение
с сервисом чата и отправляет сообщение, которое сервис должен передать получателю. Для этого хорошо подходит *заголовок Keep-Alive* , который позволяет клиенту поддерживать постоянное соединение с сервисом чата. Он также уменьшает количество TCP-согласований. Поскольку в HTTP соединение инициирует клиент, отправить сообщение с сервера клиенту не так-то просто. С годами было выработано множество способов имитации соединения, инициированного сервером: HTTP-опрос, длинный HTTP-опрос и WebSocket.

**HTTP-опрос (polling)** - состоит в том, что клиент периодически спрашивает сервер о наличии новых сообщений (после каждого такого запроса - соединение закрывается, а затем снова открывается, те слишком много накладных расходов тратятся с пустую). В зависимости от частоты опроса этот подход может быть затратным. Драгоценные ресурсы сервера могут уходить на возвращение ответа, который в большинстве случаев не несет в себе никакой полезной информации.

**Длинный HTTP-опрос (long polling)** - клиент оставляет соединение открытым, пока не появятся новые сообщения или пока не истечет время ожидания. Получив новые сообщения ( после этого соединение закрывается), клиент немедленно отправляет серверу еще один запрос, повторяя весь процесс заново. У длинного HTTP-опроса есть несколько недостатков:
  - Отправитель и получатель могут быть подключены к разным серверам чата. HTTP-серверы обычно не хранят свое состояние. Если вы балансируете нагрузку путем циклического перебора, у сервера, принявшего сообщение, может не быть соединения с клиентом, которому это сообщение направлено.
  - У сервера нет хорошего механизма для определения того, отключился ли клиент.
  - Это неэффективный подход. Если пользователь не слишком активен, время ожидания будет периодически истекать и соединение будет устанавливаться заново.

**WebSocket** - это наиболее распространенное решение для передачи асинхронных обновлений от сервера к клиенту. Соединение по WebSocket инициируется клиентом. Оно является двунаправленным и постоянным.
Все начинается с HTTP-соединения, которое можно «модернизировать» до WebSocket с помощью определенной процедуры согласования. По этому постоянному соединению сервер может отправлять обновления клиенту. Соединения по WebSocket обычно работают даже при наличии брандмауэра. Все благодаря тому, что они используют порты 80 или 443, принадлежащие протоколам HTTP/HTTPS. WebSocket работает на стороне отправителя и получателя. Использование WebSocket как для отправки, так и для получения сообщений упрощает архитектуру и делает реализацию клиента и сервера более понятной. Поскольку соединение по WebSocket является постоянным, нам нужно позаботиться об его эффективном управлении на серверной стороне. Выбор WebSocket в качестве основного протокола взаимодействия между клиентом и сервером обусловлен его двунаправленностью. 
Его необязательно использовать для всего остального. На самом деле большинство возможностей приложения (регистрация, вход в систему, профили пользователей и т. д.) могут быть реализованы в традиционном стиле «запрос–ответ» по протоколу HTTP.

**Сервисы без сохранения состояния** традиционно используются для взаимодействия с клиентами по принципу «запрос–ответ». На их основе реализованы такие функции, как вход в систему, регистрация, профили
пользователей и т. д. Сервисы без сохранения состояния находятся за балансировщиком нагрузки. Последний отвечает за маршрутизацию запросов и выбор подходящего сервиса с учетом указанного пути. 
Механизм обнаружения сервисов - основная задача этого компонента состоит в возвращении клиенту списка доменных имен, принадлежащих серверам чата, к которым можно подключиться.

**Сервисы с сохранением состояния** единственный сервис, который хранит свое состояние, — это чат. Это обу­словлено тем, что каждый клиент поддерживает постоянное сетевое соединение с сервером чата. Пока сервер остается доступным, клиент обычно не переходит на другой сервер. Чтобы серверы не перегружались, механизм обнаружения сервисов координирует свою работу с чатом.

Для такого приложения, как чат, самым важным сторонним сервисом являются **push-уведомления**. Они позволяют информировать пользователей о новых сообщениях, даже когда приложение не работает. 

Если масштаб небольшой, все сервисы, можно уместить на одном сервере. Но даже при таком масштабе все пользовательские соединения теоретически могут обрабатываться одним современным облачным сервером. Ограничивающим фактором, скорее всего, будет *количество параллельных соединений*. В нашем случае речь идет об 1 миллионе активных пользователей (DAU); если предположить, что каждое пользовательское соединение занимает 10 Кб (это очень грубая оценка, которая сильно зависит от выбранного языка программирования), то для того, чтобы все они уместились на одном сервере, потребуется 10 Гб оперативной памяти.

Архитектура на один сервер для всего - это единая точка отказа (большой минус).

Чтобы сделать обоснованный выбор *реляционная* или *NoSQL*, необходимо исследовать *типы данных* и модель *чтения/записи*.  Для чата советуем использовать хранилища типа «ключ–значение» по следующим причинам:
  - хранилища типа «ключ–значение» легко поддаются горизонталь ному масштабированию;
  - хранилища типа «ключ–значение» имеют низкую латентность обращения к данным;
  - реляционные БД плохо справляются с длинными последовательностями данных. С увеличением индекса замедляется произвольный доступ.
  - хранилища типа «ключ–значение» применяются в других надежных системах мгновенного обмена сообщениями, проверенных временем. Например, они используются в Facebook Messenger (HBase) и Discord (Cassandra).


Основная задача механизма обнаружения сервисов — предложить клиенту лучший сервер чата с учетом таких критериев, как географическое местоположение, емкость сервера и т. д. Популярное решение — система
с открытым исходным кодом Apache Zookeeper. Она регистрирует все доступные серверы чата и выбирает из них тот, который лучше всего соответствует заранее заданным критериям.








